{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hS5VEmQ8om32"
      },
      "source": [
        "# Importing the required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVFjXo_xoYc-"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.porter import PorterStemmer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow import expand_dims\n",
        "from tensorflow.math import reduce_sum\n",
        "from tensorflow.nn import tanh, softmax\n",
        "from tensorflow.keras.layers import Dense, Embedding, Conv1D, MaxPool1D, Input, LSTM, Bidirectional, Layer,Dot, Multiply, Dropout\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "# from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.dtypes import uint8, float32\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSLej1oL8Pnd",
        "outputId": "2a6a2689-6ac4-4e6b-da78-fcf48ecfe2ad"
      },
      "outputs": [],
      "source": [
        "!pip install -q keras-tcn\n",
        "from tcn import TCN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AHEqV73jotZu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.random import set_seed\n",
        "set_seed(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx7QnXUJpCLs",
        "outputId": "ec405016-c2a2-453b-d7a6-d9d9146a14b2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apidnb2bow9V"
      },
      "source": [
        "# Data Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sIhNiGsOo04H"
      },
      "outputs": [],
      "source": [
        "true = pd.read_csv('/content/drive/MyDrive/data_set_1/ISOT Fake News Dataset/True.csv')\n",
        "fake = pd.read_csv('/content/drive/MyDrive/data_set_1/ISOT Fake News Dataset/Fake.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMIo0V5ppJ5G"
      },
      "outputs": [],
      "source": [
        "# add 1 for label for true and 0 fro fake\n",
        "true[\"label\"] = 1\n",
        "fake['label'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zAOdOBtPpOLm"
      },
      "outputs": [],
      "source": [
        "# Combine both dataframes and shuffle\n",
        "input_data = pd.concat( [true,fake] )\n",
        "input_data = input_data.sample(frac = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amvJHd4dpTj0"
      },
      "outputs": [],
      "source": [
        "# remove website url and ip\n",
        "input_data['text']= input_data['text'].apply(lambda x: re.sub(r\"(https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|www\\.[a-zA-Z0-9][a-zA-Z0-9-]+[a-zA-Z0-9]\\.[^\\s]{2,}|https?:\\/\\/(?:www\\.|(?!www))[a-zA-Z0-9]+\\.[^\\s]{2,}|www\\.[a-zA-Z0-9]+\\.[^\\s]{2,})\", \"\", x))\n",
        "input_data['text']= input_data['text'].apply(lambda x: re.sub(r\"^(?!mailto:)(?:(?:http|https|ftp)://)(?:\\\\S+(?::\\\\S*)?@)?(?:(?:(?:[1-9]\\\\d?|1\\\\d\\\\d|2[01]\\\\d|22[0-3])(?:\\\\.(?:1?\\\\d{1,2}|2[0-4]\\\\d|25[0-5])){2}(?:\\\\.(?:[0-9]\\\\d?|1\\\\d\\\\d|2[0-4]\\\\d|25[0-4]))|(?:(?:[a-z\\\\u00a1-\\\\uffff0-9]+-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff0-9]+-?)*[a-z\\\\u00a1-\\\\uffff0-9]+)*(?:\\\\.(?:[a-z\\\\u00a1-\\\\uffff]{2,})))|localhost)(?::\\\\d{2,5})?(?:(/|\\\\?|#)[^\\\\s]*)?$\", \"\", x))\n",
        "input_data['text']= input_data['text'].apply(lambda x: re.sub(r\"^((25[0-5]|(2[0-4]|1[0-9]|[1-9]|)[0-9])(\\.(?!$)|$)){4}$\", \"\", x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1M3WtwWqpXRb",
        "outputId": "51d5f8d8-0a56-4998-bdc0-a9af4b6f7974"
      },
      "outputs": [],
      "source": [
        "# Remove Stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords=stopwords.words('english')\n",
        "input_data['text'] = input_data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93fQXH4rpmnM",
        "outputId": "26aa85ad-6e57-4e6a-e8f2-d67ea1646813"
      },
      "outputs": [],
      "source": [
        "#STEMMING\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xBwYPll_pqv1"
      },
      "outputs": [],
      "source": [
        "porter = PorterStemmer()\n",
        "# for word in input_data['text']:\n",
        "#     print(porter.stem(word))\n",
        "input_data['text'] = input_data['text'].apply(lambda x: ' '.join([porter.stem(y) for y in x.split()]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Douzj04tfoM"
      },
      "source": [
        "Mapping Text to Vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kCDj8me_fu9S",
        "outputId": "25bf734e-1155-42f8-fc85-eb8711a1b455"
      },
      "outputs": [],
      "source": [
        "pip install keras-preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wH0o_UxcpteF"
      },
      "outputs": [],
      "source": [
        "# Tockenization\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras_preprocessing.sequence import pad_sequences\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers import Embedding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QHcxqeipw5t"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer(num_words=9999999999)\n",
        "tokenizer.fit_on_texts(input_data['text'])\n",
        "sequences = tokenizer.texts_to_sequences(input_data['text'])\n",
        "word_index = tokenizer.word_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPpF7YFDp0Fs",
        "outputId": "ed7695b9-3f9b-4087-811f-2ed255528602"
      },
      "outputs": [],
      "source": [
        "len(sequences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ajmP7OZQrsHF"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "sequences=tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    sequences,\n",
        "    maxlen=100,\n",
        "    dtype='int32',\n",
        "    padding='post',\n",
        "    truncating='pre',\n",
        "    value=0.0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tAabIoZ-DSSq",
        "outputId": "41346ec3-bdbd-4ded-afec-c209070182ad"
      },
      "outputs": [],
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W2onaipNtoj-",
        "outputId": "74413c6a-0cb8-4477-a725-11157f21ff71"
      },
      "outputs": [],
      "source": [
        "GLOVE_DIR = \"data\"\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join(GLOVE_DIR, '/content/drive/MyDrive/data_set_1/ISOT Fake News Dataset/glove.6B.300d.txt'), encoding=\"utf8\")\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    #print(values[1:])\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Total %s word vectors in Glove.' % len(embeddings_index))\n",
        "\n",
        "embedding_matrix = np.random.random((len(word_index) + 1, 300))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            300,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h4-W2TvNTqEs"
      },
      "source": [
        "# SPLITTING THE DATA\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53PWbQDdtuPl",
        "outputId": "36c58cd4-35f1-46d4-f8c4-892ea62ea102"
      },
      "outputs": [],
      "source": [
        "data=sequences\n",
        "label= input_data[\"label\"]\n",
        "x_train, x_test, y_train, y_test = train_test_split( data, label, test_size=0.20, random_state=42)\n",
        "x_test, x_val, y_test, y_val = train_test_split( x_test, y_test, test_size=0.50, random_state=42)\n",
        "print('Size of train, validation, test:', len(y_train), len(y_val), len(y_test))\n",
        "\n",
        "print('real & fake news in train,valt,test:')\n",
        "print(y_train.sum(axis=0))\n",
        "print(y_val.sum(axis=0))\n",
        "print(y_test.sum(axis=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8T3ncgAUCcE"
      },
      "source": [
        "# MODEL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "BjclOqGT32uN",
        "outputId": "67798b57-363b-4456-eabe-8cb073760819"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/Project_Models/Processed_Data/'\n",
        "path1 = '/content/drive/MyDrive/Colab Notebooks/Project_Models/'\n",
        "x_train=pickle.load(open(path+'x_train.pkl', 'rb'))\n",
        "y_train=pickle.load(open(path+'y_train.pkl', 'rb'))\n",
        "y_test=pickle.load(open(path+'y_test.pkl', 'rb'))\n",
        "x_test=pickle.load(open(path+'x_test.pkl', 'rb'))\n",
        "x_val=pickle.load(open(path+'x_val.pkl', 'rb'))\n",
        "y_val=pickle.load(open(path+'y_val.pkl', 'rb'))\n",
        "embedding_layer = pickle.load(open(path1+'i100embedding_layer.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dGW815Pvt1pV"
      },
      "outputs": [],
      "source": [
        "class Attention(Layer):\n",
        "\n",
        "    def __init__(self, return_sequences=True):\n",
        "        self.return_sequences = return_sequences\n",
        "        super(Attention,self).__init__()\n",
        "\n",
        "    def build(self, input_shape):\n",
        "\n",
        "        self.W=self.add_weight(name=\"att_weight\", shape=(input_shape[-1],1),\n",
        "                               initializer=\"normal\")\n",
        "        self.b=self.add_weight(name=\"att_bias\", shape=(input_shape[1],1),\n",
        "                               initializer=\"zeros\")\n",
        "\n",
        "        super(Attention,self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "\n",
        "        w = expand_dims(self.W, 0)\n",
        "        e = tanh(Dot(axes = [2, 1])([x,w])+self.b)\n",
        "        a = softmax(e, axis=1)\n",
        "        output = x*a\n",
        "\n",
        "        if self.return_sequences:\n",
        "            return output\n",
        "\n",
        "        return reduce_sum(output, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SxnyTEM3tz8M"
      },
      "outputs": [],
      "source": [
        "i = Input([100], dtype=uint8)\n",
        "x = embedding_layer(i)\n",
        "# x = Conv1D(128, 5, activation='relu')(x)\n",
        "# x = MaxPool1D()(x)\n",
        "# x = LSTM(32, activation='linear')(x)\n",
        "# x = (Bidirectional(LSTM(32, activation='linear')(x))\n",
        "# prediction = Dense(1, activation='sigmoid')(x)\n",
        "# model = Model(inputs=[i], outputs=prediction)\n",
        "\n",
        "# x = Embedding(10000 + 1,\n",
        "#                             300,\n",
        "#                             # weights=[embedding_matrix],\n",
        "#                             input_length=300)(i)\n",
        "\n",
        "max_len = 200\n",
        "rnn_cell_size = 128\n",
        "vocab_size = 250\n",
        "\n",
        "x = Bidirectional(LSTM(rnn_cell_size,\n",
        "                        return_sequences=True), name=\"bi_lstm_0\")(x)\n",
        "x= Dropout(0.30)(x)\n",
        "x = Attention(return_sequences=True)(x)\n",
        "# x = LSTM(128, activation='linear', return_sequences=True)(x)\n",
        "x = TCN(return_sequences=False)(x)\n",
        "output = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "model = Model(inputs=i , outputs=output)\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# lstm, forward_h, forward_c, backward_h, backward_c =Bidirectional \\\n",
        "#     (LSTM(rnn_cell_size,\n",
        "#       return_sequences=True))(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9GBvphhKlPp",
        "outputId": "c9d162d6-c58d-44da-b3e4-268f8a3711a7"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_2sEZkSgWsEC"
      },
      "outputs": [],
      "source": [
        "class myCallback(Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    acc = logs.get('accuracy')\n",
        "    val_acc = logs.get('val_accuracy')\n",
        "    if (epoch % 5 == 0) and (epoch != 0):\n",
        "      model_name = f'BLSTM-ATT-TCN_e{epoch}'  # add model name (name_) as required\n",
        "      model_path = '/content/drive/MyDrive/Colab Notebooks/Project_Models/BLSTM_ATT_TCN_Models'  # add model path as required\n",
        "      self.model.save(os.path.join(model_path, model_name))\n",
        "\n",
        "callback = myCallback()\n",
        "\n",
        "callbacks=[callback]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mixnl7gruSYO",
        "outputId": "f167455c-27a8-44b7-9759-cbd23e809814"
      },
      "outputs": [],
      "source": [
        "BATCH_SIZE = 64\n",
        "EPOCHS = 40\n",
        "TRAINING_STEPS = len(x_train) //  BATCH_SIZE\n",
        "VALIDATION_STEPS = len(x_val) // BATCH_SIZE\n",
        "\n",
        "history = model.fit(x_train,y_train,\n",
        "                    steps_per_epoch= TRAINING_STEPS,\n",
        "                    validation_data=[x_val,y_val],\n",
        "                    validation_steps=VALIDATION_STEPS,\n",
        "                    epochs=EPOCHS,\n",
        "                    callbacks=[callback],\n",
        "                    verbose='auto')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qxLOThGfcRJ",
        "outputId": "f9e31909-f906-4259-c561-18b4e9672cd0"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/Colab Notebooks/Project_Models/Processed_Data/'\n",
        "pickle.dump(history, open(path+'history_BLSTM_ATT_TCN.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROe5eqVjUUA1"
      },
      "source": [
        "# Metrics and Graphs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        },
        "id": "q5o4YZwRlGKK",
        "outputId": "478385fd-9c4b-4772-ad97-4c0be05467b3"
      },
      "outputs": [],
      "source": [
        "# Training History\n",
        "print(history.history.keys())\n",
        "# summarize history for accuracy\n",
        "\n",
        "plt.plot(history.history['val_accuracy'], )\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e1PTD3OjJsCB"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agmSrGlBJr_J"
      },
      "outputs": [],
      "source": [
        "model=load_model('/content/drive/MyDrive/Colab Notebooks/Project_Models/BLSTM_ATT_TCN_Models/BLSTM-ATT-TCN_e35')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hdjt2jiGJr4j",
        "outputId": "f5abecd9-c8eb-4a0c-afdf-2e7f3052cca2"
      },
      "outputs": [],
      "source": [
        "y_pred=model.predict(x_test)\n",
        "y_pred = np.squeeze(y_pred)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FB5ifjA8J3Za"
      },
      "outputs": [],
      "source": [
        "p = lambda t : 1 if t>=0.5 else 0\n",
        "y_pred=np.vectorize(p)(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "id": "q58brjUsJ6Lt",
        "outputId": "f253601d-b0de-490a-e641-e7f1aa7fe46b"
      },
      "outputs": [],
      "source": [
        "conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)\n",
        "for i in range(conf_matrix.shape[0]):\n",
        "    for j in range(conf_matrix.shape[1]):\n",
        "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwS5R3KaL_GC",
        "outputId": "51366eb0-9041-4043-8aef-01b73cdff079"
      },
      "outputs": [],
      "source": [
        "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
        "print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
        "print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
        "print('F1 Score: %.3f' % f1_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8df0c3vOQ5Tg",
        "outputId": "78e053ec-11c5-4814-b79c-a750bbfecea0"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test, y_test, verbose = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 754
        },
        "id": "onlnxxVE-0Bx",
        "outputId": "4b2bb59d-f205-4ff7-855b-9a6c8657e5e3"
      },
      "outputs": [],
      "source": [
        "dot_img_file = '/tmp/model_1.png'\n",
        "tf.keras.utils.plot_model(model, to_file=dot_img_file, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxncy7ABntTH"
      },
      "outputs": [],
      "source": [
        "accuracy=[]\n",
        "val_accuracy=[]\n",
        "loss=[]\n",
        "val_loss=[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwdPmmldqcTQ"
      },
      "outputs": [],
      "source": [
        "final=['history_CNN_LSTM.pkl', 'history_CNN_BLSTM_ATT.pkl', 'history_BLSTM_ATT_TCN.pkl']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "hu3g5m3cnvF3",
        "outputId": "f4b7f644-bd0e-4761-97d2-8c32fe376a9e"
      },
      "outputs": [],
      "source": [
        "from nltk.tag.hunpos import find_binary\n",
        "for x in final:\n",
        "              history=pickle.load(open(path1+x, 'rb'))\n",
        "              accuracy.append(history.history['accuracy'])\n",
        "              val_accuracy.append(history.history['val_accuracy'])\n",
        "              loss.append(history.history['loss'])\n",
        "              val_loss.append(history.history['val_loss'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fq60KzKHy9Mm",
        "outputId": "88b2960e-4f06-4dd8-fec0-2eec2228921b"
      },
      "outputs": [],
      "source": [
        "print (*accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "Kz2DsXI3Z-ZG",
        "outputId": "2aef3846-c5f6-4c12-a175-bae9a190df1a"
      },
      "outputs": [],
      "source": [
        "for x in accuracy:\n",
        "                  plt.plot(x)\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Model 1', 'Model 2','Model 3'], loc='lower right')\n",
        "f = plt.figure()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 522
        },
        "id": "fH7tQj8C2nQ-",
        "outputId": "4591b5de-39c5-4914-91a3-aa559be998ed"
      },
      "outputs": [],
      "source": [
        "for x in val_accuracy:\n",
        "                  plt.plot(x)\n",
        "plt.ylabel('val_accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Model1', 'Model2','Model3','Model4'], loc='lower rightt')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "6kGgoM3C2wUF",
        "outputId": "159815f1-93cd-4a87-e219-3bca753a3b77"
      },
      "outputs": [],
      "source": [
        "for x in loss:\n",
        "                  plt.plot(x)\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Model1', 'Model2','Model3','Model4'], loc='upper right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "daUbgr7b21bH",
        "outputId": "25eb0fe8-1907-407b-cc0d-309c30bb837d"
      },
      "outputs": [],
      "source": [
        "for x in val_loss:\n",
        "                  plt.plot(x)\n",
        "plt.ylabel('val_loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['Model1', 'Model2','Model3','Model4'], loc='upper right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h4-W2TvNTqEs"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
